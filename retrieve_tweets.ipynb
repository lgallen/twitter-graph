{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Social Graph From Twitter \n",
    "\n",
    "This Python notebook is used to create a social graph from a community on Twitter. I have tried to write this notebook in such a way that it would be accessible to a wide audience. The idea is to use a hashtag from that would be commonly used by a Twitter community and not by others, such as a chat hashtag for a Twitter chat being held at a specific time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tweepy #https://github.com/tweepy/tweepy\n",
    "import csv\n",
    "import pandas as pd\n",
    "# Used for progress bar\n",
    "import time\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Twitter API Credentials\n",
    "\n",
    "Although registration is required, Twitter API credentials are freely available to anyone.\n",
    "\n",
    "https://dev.twitter.com/oauth/overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Twitter API credentials\n",
    "consumer_key = \"\"\n",
    "consumer_secret = \"\"\n",
    "access_key = \"\"\n",
    "access_secret = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "OAUTH_KEYS = {'consumer_key':consumer_key, 'consumer_secret':consumer_secret,\n",
    " 'access_token_key':access_key, 'access_token_secret':access_secret}\n",
    "auth = tweepy.OAuthHandler(OAUTH_KEYS['consumer_key'], OAUTH_KEYS['consumer_secret'])\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Searching Twitter\n",
    "Search for whatever trait your community has in common. In this case, I searched for a popular Twitter hashtag, limiting the results to the 4000 most recent Tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "search = tweepy.Cursor(api.search, q='#edtechchat').items(4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create lists for each field desired from the tweets.\n",
    "sn = []\n",
    "text = []\n",
    "timestamp =[]\n",
    "for tweet in search:\n",
    "    #print tweet.user.screen_name, tweet.created_at, tweet.text\n",
    "    timestamp.append(tweet.created_at)\n",
    "    sn.append(tweet.user.screen_name)\n",
    "    text.append(tweet.text)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert lists to dataframe\n",
    "df = pd.DataFrame()\n",
    "df['timestamp'] = timestamp\n",
    "df['sn'] = sn\n",
    "df['text'] = text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Prepare ford date filtering. Adding an EST time column since chat hosted by people in that time zone.\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "df['EST'] = df['timestamp'] - pd.Timedelta(hours=5) #Convert to EST\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['EST'] = pd.to_datetime(df['EST'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Subset for the dates required. Can select a specific date or time to examine.\n",
    "import time\n",
    "df = df[(pd.to_datetime(\"2015-12-14 20:00:00\", format='%Y-%m-%d %H:%M:%S') < df['EST']) & (df['EST'] < pd.to_datetime(\"2015-12-14 21:00:00\", format='%Y-%m-%d %H:%M:%S'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Write out Tweets in case they are needed later.\n",
    "df.to_csv('edtechtweets.csv',index = False,encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a list of the unique usernames in order to see which users we need to retrieve friends for.\n",
    "allNames = list(df['sn'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve User Information\n",
    "\n",
    "Now having a list of all of the users we would like to include in our community, we can retrive additional necessary information such as who their are following in order to build our social graph.\n",
    "\n",
    "Note that Twitter does have strict rate limits that can cause problems at this point. A timeout is built into every iteration to minimize this. If problems still occur, you may want to include an intermediate write out on every iteration to maintain what has been captured to that point. The loop can be restarted from the nth value of allNames where a break occurs (i.e. \"for name in allNames[n:]\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialize dataframe of users that will hold the edge relationships\n",
    "dfUsers = pd.DataFrame()\n",
    "dfUsers['userFromName'] =[]\n",
    "dfUsers['userFromId'] =[]\n",
    "dfUsers['userToId'] = []\n",
    "count = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nameCount = len(allNames)\n",
    "# The choice to retrieve friends (who the user is following) rather than followers is intentional.\n",
    "# Either would work. However, many Twitter users follow fewer users than are following them, especially the most popular accounts. \n",
    "# This reduces the number of very large calls to Twitter API, which seemed to cause problems.\n",
    "for name in allNames:\n",
    "    # Build list of friends    \n",
    "    currentFriends = []\n",
    "    for page in tweepy.Cursor(api.friends_ids, screen_name=name).pages():\n",
    "        currentFriends.extend(page)\n",
    "    currentId = api.get_user(screen_name=name).id\n",
    "    currentId = [currentId] * len(currentFriends)\n",
    "    currentName = [name] * len(currentFriends)   \n",
    "    dfTemp = pd.DataFrame()\n",
    "    dfTemp['userFromName'] = currentName\n",
    "    dfTemp['userFromId'] = currentId\n",
    "    dfTemp['userToId'] = currentFriends\n",
    "    dfUsers = pd.concat([dfUsers,dfTemp])\n",
    "    time.sleep(70) # avoids hitting Twitter rate limit\n",
    "    # Progress bar to track approximate progress\n",
    "    count +=1\n",
    "    per = round(count*100.0/nameCount,1)\n",
    "    sys.stdout.write(\"\\rTwitter call %s%% complete.\" % per)\n",
    "    sys.stdout.flush()    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Again, to limit the number of calls to Twitter API, just do lookups on followers that connect to those in our user group.\n",
    "# We are not interested in \"friends\" that are not part of this community.\n",
    "fromId = dfUsers['userFromId'].unique()\n",
    "dfChat = dfUsers[dfUsers['userToId'].apply(lambda x: x in fromId)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# No more Twitter API lookups are necessary. Create a lookup table that we will use to get the verify the userToName\n",
    "dfLookup = dfChat[['userFromName','userFromId']]\n",
    "dfLookup = dfLookup.drop_duplicates()\n",
    "dfLookup.columns = ['userToName','userToId']\n",
    "dfCommunity = dfCommunity.merge(dfLookup, on='userToId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfCommunity.to_csv('dfCommunity.csv',index = False,encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
